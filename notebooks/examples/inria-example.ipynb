{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "!pip install buzzard",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:25:39.918087Z",
          "iopub.execute_input": "2021-08-24T03:25:39.918661Z",
          "iopub.status.idle": "2021-08-24T03:25:50.284555Z",
          "shell.execute_reply.started": "2021-08-24T03:25:39.918524Z",
          "shell.execute_reply": "2021-08-24T03:25:50.283623Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "!pip install segmentation-models-pytorch",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:26:06.972560Z",
          "iopub.execute_input": "2021-08-24T03:26:06.972893Z",
          "iopub.status.idle": "2021-08-24T03:26:17.850811Z",
          "shell.execute_reply.started": "2021-08-24T03:26:06.972860Z",
          "shell.execute_reply": "2021-08-24T03:26:17.849869Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport buzzard as buzz\nimport matplotlib.pyplot as plt\nfrom os import listdir\nfrom os.path import isfile, join\nimport tqdm\nimport os",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:26:27.513942Z",
          "iopub.execute_input": "2021-08-24T03:26:27.514268Z",
          "iopub.status.idle": "2021-08-24T03:26:32.171624Z",
          "shell.execute_reply.started": "2021-08-24T03:26:27.514235Z",
          "shell.execute_reply": "2021-08-24T03:26:32.170591Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom tensorflow.keras.utils import Sequence\nimport cv2 as cv",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:27:43.617039Z",
          "iopub.execute_input": "2021-08-24T03:27:43.617369Z",
          "iopub.status.idle": "2021-08-24T03:27:47.818052Z",
          "shell.execute_reply.started": "2021-08-24T03:27:43.617321Z",
          "shell.execute_reply": "2021-08-24T03:27:47.817111Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "image_size = 256\ndata_folder = '../input/inria-aerial-image-labeling-dataset/AerialImageDataset'\ntrain_folder_final='./train'\n\nsrc_train_folder = os.path.join(data_folder, 'train', 'images')\nsrc_train_folder_gt = os.path.join(data_folder, 'train', 'gt')\nsrc_test_folder = os.path.join(data_folder, 'test', 'images')\n\nsrc_train_images = os.listdir(src_train_folder)\nsrc_test_images = os.listdir(src_test_folder)\n\ntrain_folder_root = os.path.join(train_folder_final.format(image_size, image_size))\ntrain_folder = os.path.join(train_folder_root, 'images')\ntrain_folder_gt = os.path.join(train_folder_root, 'gt')\n\n\ndef create_gaussian(size=image_size, sigma=0.55):\n    x, y = np.meshgrid(np.linspace(-1, 1, size), np.linspace(-1, 1, size))\n    d = np.sqrt(x * x + y * y)\n    gaussian = np.exp(-(d ** 2 / (2.0 * sigma ** 2)))\n    return gaussian\n\n\nclass DataAugmentation(Sequence):\n\n    def __init__(self, batch_size, validation, validation_set, process_input, border, debug=False):\n        assert(0 <= validation_set <= 6)\n        self.batch_size = batch_size\n        self.validation = validation\n        self.validation_set = validation_set\n        self.process_input = process_input\n        self.border = border\n        self.debug = debug\n\n        if self.debug:\n            if not os.path.exists(debug_folder):\n                os.makedirs(debug_folder)\n\n        # Build image list\n        self.images = []\n        for fname in os.listdir(train_folder):\n            name = fname.split('_')[0]\n            i = len(name) - 1\n            while name[i].isdigit():\n                i -= 1\n            i += 1\n            n = int(name[i:])\n            if validation_set > 0:\n                if self.validation:\n                    if (n - 1) // 6 == self.validation_set - 1:\n                        self.images.append(fname)\n                else:\n                    if (n - 1) // 6 != self.validation_set - 1:\n                        self.images.append(fname)\n            elif not self.validation:\n                self.images.append(fname)\n\n        # Shuffle data\n        if self.validation:\n            self.images = np.random.RandomState(0).permutation(self.images)\n            print(\"validation_elements = \" + str(len(self.images)))\n        else:\n            self.images = np.random.RandomState(0).permutation(self.images)\n            print(\"training_elements = \" + str(len(self.images)))\n\n        # Create border structuring element\n        if self.border:\n            self.structuring_element = cv.getStructuringElement(cv.MORPH_RECT, (3, 3))\n\n    def __len__(self):\n        return int(np.ceil(len(self.images) / self.batch_size))\n\n    def __getitem__(self, idx):\n        batch_start = idx * self.batch_size\n        batch_end = min(len(self.images), (idx + 1) * self.batch_size)\n        batch_images = self.images[batch_start:batch_end]\n\n        batch_x = np.zeros((len(batch_images), image_size, image_size, 3), dtype=np.float32)\n        if self.border:\n            batch_y = np.zeros((len(batch_images), image_size, image_size, 2), dtype=np.float32)\n        else:\n            batch_y = np.zeros((len(batch_images), image_size, image_size, 1), dtype=np.float32)\n\n        for i in range(len(batch_images)):\n            fname = batch_images[i]\n            fpath = os.path.join(train_folder, fname)\n            fpath_gt = os.path.join(train_folder_gt, fname[:-4] + '.png')\n            image = cv.imread(fpath)\n            image_gt = cv.imread(fpath_gt, 0)\n            image_gt = np.expand_dims(image_gt, -1)\n\n            if not self.validation:\n                t = self.get_random_transform()\n                image = self.transform(image, t)\n                image_gt = self.transform(image_gt, t)\n\n            batch_x[i] = self.process_input(image)\n\n            if self.border:\n                border = cv.dilate(image_gt, self.structuring_element) - cv.erode(image_gt, self.structuring_element)\n                border = np.reshape(border, (image_size, image_size, 1))\n                batch_y[i] = np.concatenate((image_gt, border), axis=-1) / 255\n            else:\n                batch_y[i] = image_gt / 255\n\n            if self.debug:\n                cv.imwrite(os.path.join(debug_folder, fname), image)\n                cv.imwrite(os.path.join(debug_folder, fname[:-4] + '.png'), image_gt)\n                if self.border:\n                    cv.imwrite(os.path.join(debug_folder, fname[:-4] + '_b.png'), border)\n\n        return batch_x, batch_y\n\n    @staticmethod\n    def get_random_transform():\n        tc = 6\n        t = min(tc-1, int(np.floor(tc * np.random.rand())))\n        return t\n\n    @staticmethod\n    def transform(img, t):\n        if t == 1:\n            return np.fliplr(img)\n        if t == 2:\n            return np.flipud(img)\n        if t == 3:\n            return np.rot90(img, 2)\n        if t == 4:\n            return np.rot90(img, -1)\n        if t == 5:\n            return np.rot90(img, 1)\n        return img\n\n    @staticmethod\n    def inverse_transform(img, t):\n        if t == 1:\n            return np.fliplr(img)\n        if t == 2:\n            return np.flipud(img)\n        if t == 3:\n            return np.rot90(img, -2)\n        if t == 4:\n            return np.rot90(img, 1)\n        if t == 5:\n            return np.rot90(img, -1)\n        return img\n\n\ndef test_data_augmentation():\n    img = cv.imread(os.path.join(train_folder, 'austin1_9_0.jpg'))\n    for i in range(100):\n        t = DataAugmentation.get_random_transform()\n        img_aug = DataAugmentation.transform(img, t)\n        img_aug = np.clip(img_aug, 0, 255).astype(np.uint8)\n        cv.imwrite(os.path.join(tmp_folder, str(i) + '.jpg'), img_aug)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:27:50.144484Z",
          "iopub.execute_input": "2021-08-24T03:27:50.145035Z",
          "iopub.status.idle": "2021-08-24T03:27:50.198464Z",
          "shell.execute_reply.started": "2021-08-24T03:27:50.144994Z",
          "shell.execute_reply": "2021-08-24T03:27:50.197610Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport cv2 as cv\nimport shutil\nimport math\nmaster_size = 1000\noverlap = 0.3\nthreshold = 0.45\n\ntest = False\n\ncount = math.ceil((master_size - image_size * overlap) / (image_size * (1 - overlap)))\nstep = (master_size - image_size * overlap) / count\nprint('count =', count, ', step =', step)\n\nif not os.path.exists(train_folder_root):\n    os.makedirs(train_folder_root)\n\nif not os.path.exists(train_folder):\n    os.makedirs(train_folder)\nelse:\n    shutil.rmtree(train_folder)\n\nif not os.path.exists(train_folder_gt):\n    os.makedirs(train_folder_gt)\nelse:\n    shutil.rmtree(train_folder_gt)\n\nfor filename in src_train_images:\n    print(filename)\n    master_img = cv.imread(os.path.join(src_train_folder, filename))\n    master_img_gt = cv.imread(os.path.join(src_train_folder_gt, filename))\n\n    for i in range(count):\n        if i < count - 1:\n            y = round(i * step)\n        else:\n            y = master_size - image_size\n\n        for j in range(count):\n            if j < count - 1:\n                x = round(j * step)\n            else:\n                x = master_size - image_size\n\n            img = master_img[y:y+image_size, x:x+image_size]\n            img_gt = master_img_gt[y:y+image_size, x:x+image_size]\n\n            img_fname = '{}_{}_{}.{}'.format(filename[:-4], i, j, 'jpg')\n            img_gt_fname = '{}_{}_{}.{}'.format(filename[:-4], i, j, 'png')\n            cv.imwrite(os.path.join(train_folder, img_fname), img)\n            cv.imwrite(os.path.join(train_folder_gt, img_gt_fname), img_gt)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:27:54.854882Z",
          "iopub.execute_input": "2021-08-24T03:27:54.855206Z",
          "iopub.status.idle": "2021-08-24T03:31:35.469837Z",
          "shell.execute_reply.started": "2021-08-24T03:27:54.855176Z",
          "shell.execute_reply": "2021-08-24T03:31:35.468800Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "%matplotlib inline\nimport cv2\nfrom matplotlib import pyplot as plt\nimage = cv2.imread(\"./train/images/austin1_1_0.jpg\")\nplt.imshow(image)\nplt.show()",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:34:37.793581Z",
          "iopub.execute_input": "2021-08-24T03:34:37.793910Z",
          "iopub.status.idle": "2021-08-24T03:34:37.948154Z",
          "shell.execute_reply.started": "2021-08-24T03:34:37.793882Z",
          "shell.execute_reply": "2021-08-24T03:34:37.947274Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "!pip install torchsummary",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:34:54.018819Z",
          "iopub.execute_input": "2021-08-24T03:34:54.019175Z",
          "iopub.status.idle": "2021-08-24T03:35:00.159923Z",
          "shell.execute_reply.started": "2021-08-24T03:34:54.019140Z",
          "shell.execute_reply": "2021-08-24T03:35:00.158969Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset , DataLoader\nfrom torchvision import transforms as T\nimport torchvision\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nfrom PIL import Image\nimport cv2\nimport albumentations as A\n\nimport time \nfrom tqdm.notebook import tqdm\nfrom torchsummary import summary\nimport segmentation_models_pytorch as smp\n\ndevice =torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:34:46.018908Z",
          "iopub.execute_input": "2021-08-24T03:34:46.019242Z",
          "iopub.status.idle": "2021-08-24T03:34:49.168072Z",
          "shell.execute_reply.started": "2021-08-24T03:34:46.019208Z",
          "shell.execute_reply": "2021-08-24T03:34:49.167063Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "images= \"./train/images/\"\ntargets= \"./train/gt/\"\n\nn_classes = 2\n\ndef _df_():\n  name = []\n  for dirname ,_ , filenames in os.walk(images):\n    for filename in filenames:\n      name.append(filename.split('.')[0])\n    \n    return pd.DataFrame({'id':name} , index = np.arange(0, len(name)))\n\ndf = _df_()\nprint(len(df))",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:35:04.363715Z",
          "iopub.execute_input": "2021-08-24T03:35:04.364049Z",
          "iopub.status.idle": "2021-08-24T03:35:04.393001Z",
          "shell.execute_reply.started": "2021-08-24T03:35:04.364014Z",
          "shell.execute_reply": "2021-08-24T03:35:04.391911Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "X_train , X_val = train_test_split(df['id'].values , test_size\n                                   =0.25, random_state =19)\nprint(f'Train : {len(X_train)}')\nprint(f'Val : {len(X_val)}')",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:35:07.568117Z",
          "iopub.execute_input": "2021-08-24T03:35:07.568477Z",
          "iopub.status.idle": "2021-08-24T03:35:07.584657Z",
          "shell.execute_reply.started": "2021-08-24T03:35:07.568444Z",
          "shell.execute_reply": "2021-08-24T03:35:07.583688Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "img = Image.open(images + df['id'][0] + '.jpg')\ntarg = Image.open(targets + df['id'][0] + '.png')\n\nprint('Image Size', np.asarray(img).shape)\nprint('Mask Size' , np.asarray(targ).shape)\n\nplt.figure(figsize=(10,10))\nplt.imshow(img)\nplt.imshow(targ , alpha =0.4)\nplt.show()",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:35:11.207928Z",
          "iopub.execute_input": "2021-08-24T03:35:11.208273Z",
          "iopub.status.idle": "2021-08-24T03:35:11.594605Z",
          "shell.execute_reply.started": "2021-08-24T03:35:11.208241Z",
          "shell.execute_reply": "2021-08-24T03:35:11.593698Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def dense_target(tar: np.ndarray):\n    classes =np.unique(tar)\n    dummy= np.zeros_like(tar)\n    for idx , value in enumerate(classes):\n        mask = np.where(tar == value)\n        dummy[mask] = idx\n    return dummy\n\nclass SegData(Dataset):\n\n  def __init__(self , image_path , target_path , X , mean , std , transform =None , test=False):\n    self.image_path = image_path\n    self.target_path = target_path\n    self.X = X\n    self.transform =transform\n    self.mean = mean\n    self.std = std\n    self.test =test\n\n  def __len__(self):\n    return len(self.X)\n  \n  def __getitem__(self, idx):\n    img = cv2.cvtColor(cv2.imread(self.image_path + self.X[idx] + '.jpg') , cv2.COLOR_BGR2RGB)\n    target = cv2.imread(self.target_path + self.X[idx] + '.png' , cv2.IMREAD_GRAYSCALE)\n    kernel_sharp = np.array(([-2, -2, -2], [-2, 17, -2], [-2, -2, -2]), dtype='int')\n    img = cv2.filter2D(img, -1, kernel_sharp)\n    target = cv2.filter2D(target, -1, kernel_sharp)\n    img = cv2.resize(img, (256 , 256) , interpolation = cv2.INTER_NEAREST)\n    target = cv2.resize(target , (256 , 256), interpolation = cv2.INTER_NEAREST)\n    target = np.where( target > 0,255,0)\n  \n    if self.transform is not None:\n      aug = self.transform(image = img , target = target )\n      img = Image.fromarray(aug['image'])\n      target = aug['target']\n    \n    if self.transform is None:\n      img = Image.fromarray(img) \n    \n    t = T.Compose([T.ToTensor() , T.Normalize(self.mean , self.std)])\n    \n    if self.test is False:\n      img = t(img)\n    target = dense_target(target)\n    target = torch.from_numpy(target).long()\n    return img ,target",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:35:17.586522Z",
          "iopub.execute_input": "2021-08-24T03:35:17.586843Z",
          "iopub.status.idle": "2021-08-24T03:35:17.599429Z",
          "shell.execute_reply.started": "2021-08-24T03:35:17.586815Z",
          "shell.execute_reply": "2021-08-24T03:35:17.598561Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "mean = [0.485 ,0.456 ,0.406]\nstd = [0.229 , 0.224 , 0.225]\n\ntrain_set = SegData(images, targets, X_train , mean, std)\nval_set = SegData(images , targets , X_val , mean , std)\n\nbatch_size = 4\ntrain_loader= DataLoader(train_set , batch_size= batch_size , shuffle =True)\nval_loader = DataLoader(val_set , batch_size = batch_size , shuffle =True)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:35:20.960669Z",
          "iopub.execute_input": "2021-08-24T03:35:20.961094Z",
          "iopub.status.idle": "2021-08-24T03:35:20.971664Z",
          "shell.execute_reply.started": "2021-08-24T03:35:20.961044Z",
          "shell.execute_reply": "2021-08-24T03:35:20.970785Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x , y =next(iter(train_loader))\n\nprint(f' x = shape : {x.shape} ; type :{x.dtype}')\nprint(f' x = min : {x.min()} ; max : {x.max()}')\nprint(f' y = shape: {y.shape}; class : {y.unique()}; type: {y.dtype}')",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:35:23.969080Z",
          "iopub.execute_input": "2021-08-24T03:35:23.969448Z",
          "iopub.status.idle": "2021-08-24T03:35:24.071346Z",
          "shell.execute_reply.started": "2021-08-24T03:35:23.969419Z",
          "shell.execute_reply": "2021-08-24T03:35:24.070426Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model = smp.UnetPlusPlus('resnet50',encoder_weights='imagenet', classes = 2, activation=None,\n                 encoder_depth= 5, decoder_channels=[256,128, 64, 32,16])\nmodel=model.to(device)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:35:30.327019Z",
          "iopub.execute_input": "2021-08-24T03:35:30.327382Z",
          "iopub.status.idle": "2021-08-24T03:35:44.452227Z",
          "shell.execute_reply.started": "2021-08-24T03:35:30.327343Z",
          "shell.execute_reply": "2021-08-24T03:35:44.451308Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "summary(model, input_size=(3, 256 , 256))",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:36:28.916163Z",
          "iopub.execute_input": "2021-08-24T03:36:28.916664Z",
          "iopub.status.idle": "2021-08-24T03:36:29.897781Z",
          "shell.execute_reply.started": "2021-08-24T03:36:28.916624Z",
          "shell.execute_reply": "2021-08-24T03:36:29.896934Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def pixel_wise_accuracy(output , mask):\n  with torch.no_grad():\n    output = torch.argmax(F.softmax(output , dim =1) , dim=1)\n    correct = torch.eq(output , mask).int()\n    accuracy = float(correct.sum())/ float(correct.numel())#total number\n  return accuracy",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:36:34.327596Z",
          "iopub.execute_input": "2021-08-24T03:36:34.327934Z",
          "iopub.status.idle": "2021-08-24T03:36:34.335019Z",
          "shell.execute_reply.started": "2021-08-24T03:36:34.327904Z",
          "shell.execute_reply": "2021-08-24T03:36:34.333883Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def IoU(pred , true_pred , smooth =1e-10 , n_classes=2):\n  with torch.no_grad():\n    pred = torch.argmax(F.softmax(pred , dim =1) , dim=1)\n    pred = pred.contiguous().view(-1)\n    true_pred = true_pred.contiguous().view(-1)\n\n    iou_class = []\n    for value in range(0, n_classes):\n      true_class = pred == value\n      true_label = true_pred == value\n\n      if true_label.long().sum().item()==0:\n        iou_class.append(np.nan)\n        \n      else:\n    \n        inter = torch.logical_and(true_class, true_label).sum().float().item()\n        union = torch.logical_or(true_class , true_label).sum().float().item()\n\n        iou = (inter + smooth)/(union + smooth)\n        iou_class.append(iou)\n\n    return np.nanmean(iou_class)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:36:36.638284Z",
          "iopub.execute_input": "2021-08-24T03:36:36.638641Z",
          "iopub.status.idle": "2021-08-24T03:36:36.646009Z",
          "shell.execute_reply.started": "2021-08-24T03:36:36.638612Z",
          "shell.execute_reply": "2021-08-24T03:36:36.645127Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def DiceBceLoss(true, logits, eps=1e-7):\n    num_classes = logits.shape[1]\n    if num_classes == 1:\n        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n        pos_prob = torch.sigmoid(logits)\n        neg_prob = 1 - pos_prob\n        probas = torch.cat([pos_prob, neg_prob], dim=1)\n    else:\n        true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n        probas = F.softmax(logits, dim=1)\n    true_1_hot = true_1_hot.type(logits.type())\n    dims = (0,) + tuple(range(2, true.ndimension()))\n    intersection = torch.sum(probas * true_1_hot, dims)\n    cardinality = torch.sum(probas + true_1_hot, dims)\n    dice_loss = 1- ((2.*intersection + eps)/(cardinality + eps)).mean()\n    bce = F.cross_entropy(logits, true , reduction =\"mean\")\n    dice_bce = bce + dice_loss\n    return dice_bce",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:36:39.145543Z",
          "iopub.execute_input": "2021-08-24T03:36:39.145870Z",
          "iopub.status.idle": "2021-08-24T03:36:39.156565Z",
          "shell.execute_reply.started": "2021-08-24T03:36:39.145842Z",
          "shell.execute_reply": "2021-08-24T03:36:39.154471Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit(epochs, model, train_loader, val_loader, optimizer, scheduler, patch=False):\n    train_losses = []\n    test_losses = []\n    val_iou = []; val_acc = []\n    train_iou = []; train_acc = []\n    lrs = []\n    min_loss = np.inf\n    decrease = 1 ; not_improve=0\n\n    model.to(device)\n    fit_time = time.time()\n    for e in range(epochs):\n        since = time.time()\n        running_loss = 0\n        iou_score = 0\n        accuracy = 0\n        #training loop\n        model.train()\n        for i, data in enumerate(tqdm(train_loader)):\n            #training phase\n            image_tiles, mask_tiles = data\n            if patch:\n                bs, n_tiles, c, h, w = image_tiles.size()\n\n                image_tiles = image_tiles.view(-1,c, h, w)\n                mask_tiles = mask_tiles.view(-1, h, w)\n            \n            image = image_tiles.to(device); mask = mask_tiles.to(device);\n            #forward\n            output = model(image)\n            loss = DiceBceLoss(mask, output)\n            #evaluation metrics\n            iou_score += IoU(output, mask)\n            accuracy += pixel_wise_accuracy(output, mask)\n            #backward\n            loss.backward()\n            optimizer.step() #update weight          \n            optimizer.zero_grad() #reset gradient\n            \n            #step the learning rate\n            lrs.append(get_lr(optimizer))\n            scheduler.step() \n            \n            running_loss += loss.item()\n            \n        else:\n            model.eval()\n            test_loss = 0\n            test_accuracy = 0\n            val_iou_score = 0\n            #validation loop\n            with torch.no_grad():\n                for i, data in enumerate(tqdm(val_loader)):\n                    #reshape to 9 patches from single image, delete batch size\n                    image_tiles, mask_tiles = data\n\n                    if patch:\n                        bs, n_tiles, c, h, w = image_tiles.size()\n\n                        image_tiles = image_tiles.view(-1,c, h, w)\n                        mask_tiles = mask_tiles.view(-1, h, w)\n                    \n                    image = image_tiles.to(device); mask = mask_tiles.to(device);\n                    output = model(image)\n                    #evaluation metrics\n                    val_iou_score +=  IoU(output, mask)\n                    test_accuracy += pixel_wise_accuracy(output, mask)\n                    #loss\n                    loss = DiceBceLoss(mask, output)                                  \n                    test_loss += loss.item()\n            \n            #calculatio mean for each batch\n            train_losses.append(running_loss/len(train_loader))\n            test_losses.append(test_loss/len(val_loader))\n\n\n            if min_loss > (test_loss/len(val_loader)):\n                print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, (test_loss/len(val_loader))))\n                min_loss = (test_loss/len(val_loader))\n                decrease += 1\n                print('saving model...')\n                torch.save(model, 'model-{:.3f}.pt'.format(val_iou_score/len(val_loader)))\n                    \n\n            # if (test_loss/len(val_loader)) > min_loss:\n            #     not_improve += 1\n            #     min_loss = (test_loss/len(val_loader))\n            #     print(f'Loss did not  Decrease for {not_improve} time')\n            #     if not_improve == 7:\n            #         print('Loss did not decrease for the 7th time , Stop Training')\n            #         break\n            \n            #iou\n            val_iou.append(val_iou_score/len(val_loader))\n            train_iou.append(iou_score/len(train_loader))\n            train_acc.append(accuracy/len(train_loader))\n            val_acc.append(test_accuracy/ len(val_loader))\n            print(\"Epoch:{}/{}..\".format(e+1, epochs),\n                  \"Train Loss: {:.3f}..\".format(running_loss/len(train_loader)),\n                  \"Val Loss: {:.3f}..\".format(test_loss/len(val_loader)),\n                  \"Train IoU:{:.3f}..\".format(iou_score/len(train_loader)),\n                  \"Val IoU: {:.3f}..\".format(val_iou_score/len(val_loader)),\n                  \"Train Acc:{:.3f}..\".format(accuracy/len(train_loader)),\n                  \"Val Acc:{:.3f}..\".format(test_accuracy/len(val_loader)),\n                  \"Time: {:.2f}m\".format((time.time()-since)/60))\n        \n    history = {'train_loss' : train_losses, 'val_loss': test_losses,\n               'train_miou' :train_iou, 'val_miou':val_iou,\n               'train_acc' :train_acc, 'val_acc':val_acc,\n               'lrs': lrs}\n    print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n    return history",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:51:08.181492Z",
          "iopub.execute_input": "2021-08-24T03:51:08.181839Z",
          "iopub.status.idle": "2021-08-24T03:51:08.203577Z",
          "shell.execute_reply.started": "2021-08-24T03:51:08.181809Z",
          "shell.execute_reply": "2021-08-24T03:51:08.201407Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "max_lr = 1e-3\nepoch = 20\nweight_decay = 1e-6\n\noptimizer = torch.optim.Adam(model.parameters(), lr=max_lr, weight_decay=weight_decay)\nsched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch,\n                                            steps_per_epoch=len(train_loader))\n\nhistory = fit(epoch, model, train_loader, val_loader, optimizer, sched)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T03:51:12.609415Z",
          "iopub.execute_input": "2021-08-24T03:51:12.609738Z",
          "iopub.status.idle": "2021-08-24T06:37:53.939265Z",
          "shell.execute_reply.started": "2021-08-24T03:51:12.609711Z",
          "shell.execute_reply": "2021-08-24T06:37:53.937931Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "test_set = SegData(images, targets, X_val ,mean , std, transform = None , test = True)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T06:52:15.197536Z",
          "iopub.execute_input": "2021-08-24T06:52:15.197968Z",
          "iopub.status.idle": "2021-08-24T06:52:15.204655Z",
          "shell.execute_reply.started": "2021-08-24T06:52:15.197927Z",
          "shell.execute_reply": "2021-08-24T06:52:15.203297Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def predict_image_mask(model, image , mask , mean=[0.485, 0.456, 0.406],\n                       std = [0.229 , 0.224 ,0.225]):\n  model.eval()\n  t= T.Compose([T.ToTensor() ,T.Normalize(mean, std)])\n  image = t(image)\n  model.to(device) ; image = image.to(device)\n  mask = mask.to(device)\n  with torch.no_grad():\n\n    image = image.unsqueeze(0)\n    mask = mask.unsqueeze(0)\n\n    output = model(image)\n    score = IoU(output, mask)\n    masked = torch.argmax(output , dim =1)\n    masked = masked.cpu().squeeze(0)\n  return masked , score",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T06:53:16.045202Z",
          "iopub.execute_input": "2021-08-24T06:53:16.045569Z",
          "iopub.status.idle": "2021-08-24T06:53:16.054473Z",
          "shell.execute_reply.started": "2021-08-24T06:53:16.045538Z",
          "shell.execute_reply": "2021-08-24T06:53:16.053448Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import random\nfor i in range(10,20):\n  image , mask = test_set[i]\n  pred_mask , score = predict_image_mask(model , image , mask)\n  fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20,10))\n  ax1.imshow(image)\n  ax1.set_title('Picture');\n\n  ax2.imshow(mask)\n  ax2.set_title('Ground truth')\n  ax2.set_axis_off()\n\n  ax3.imshow(pred_mask)\n  ax3.set_title('UNet-Resnet50 | DiceBCE {:.3f}'.format(score))\n  ax3.set_axis_off()",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-24T06:56:32.009939Z",
          "iopub.execute_input": "2021-08-24T06:56:32.010297Z",
          "iopub.status.idle": "2021-08-24T06:56:36.604837Z",
          "shell.execute_reply.started": "2021-08-24T06:56:32.010266Z",
          "shell.execute_reply": "2021-08-24T06:56:36.603885Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}