{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "from src.datasets.utils.ResizeToDivisibleBy32 import ResizeToDivisibleBy32\n",
    "from src.datasets.INRIAAerialImageLabellingDatasetPatches import (\n",
    "    INRIAAerialImageLabellingDatasetPatches,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INRIA_DATASET_PATH = \"data/INRIAAerialImageLabellingDatasetPatches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n"
     ]
    }
   ],
   "source": [
    "labeled_dataset = INRIAAerialImageLabellingDatasetPatches(\n",
    "    INRIA_DATASET_PATH,\n",
    "    split=\"train\",\n",
    "    transforms=[\n",
    "        ResizeToDivisibleBy32()\n",
    "    ],\n",
    ")\n",
    "print(len(labeled_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14400\n"
     ]
    }
   ],
   "source": [
    "test_dataset = INRIAAerialImageLabellingDatasetPatches(\n",
    "    INRIA_DATASET_PATH,\n",
    "    split=\"test\",\n",
    "    transforms=[\n",
    "        ResizeToDivisibleBy32()\n",
    "    ],\n",
    ")\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(labeled_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512, 512])\n",
      "torch.Size([1, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "for image, mask in train_loader:\n",
    "    print(image.shape)\n",
    "    print(mask.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512, 512])\n",
      "torch.float32\n",
      "tensor([0.0062, 0.0075, 0.0078,  ..., 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(image.shape)\n",
    "print(image.dtype)\n",
    "print(image.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512, 512])\n",
      "torch.uint8\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "        115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
      "        129, 130, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145,\n",
      "        146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160,\n",
      "        161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,\n",
      "        175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188,\n",
      "        189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202,\n",
      "        203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n",
      "        217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
      "        231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
      "        245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255],\n",
      "       dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(mask.shape)\n",
    "print(mask.dtype)\n",
    "print(mask.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pil_transform = ToPILImage()\n",
    "img = to_pil_transform(image.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.save(\"test-img.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = to_pil_transform(mask.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk.save(\"test-msk.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "for image in test_loader:\n",
    "    print(image.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
